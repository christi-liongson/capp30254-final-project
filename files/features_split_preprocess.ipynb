{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose of this to carry out the following:\n",
    "    # explore features we already have and create new ones\n",
    "    # once that is done, carry out an appropriate train/test/validate split - taking temporal validation into account\n",
    "    # pre processing (impute missingness separately for train/test/validate, normalize, etc)\n",
    "\n",
    "# The datasets used are the datasets created by build_dataset - they're\n",
    "# too big for github, so they have been uploaded to google drive. They should\n",
    "# be downloaded into your local data folder to be imported in this notebook\n",
    "\n",
    "# The end goal of this notebook is to have our final datasets ready for analysis\n",
    "# this code should then be moved into our .py files so the notebook can eventually be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import config\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "#from create_db import create_connection, create_table, clean_column_names\n",
    "#from populate_db import extract_data, insert_records\n",
    "#import query_db as qd\n",
    "\n",
    "import importlib\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets created in build_dataset\n",
    "\n",
    "dataset_main = pd.read_csv('../data/dataset_main.csv')\n",
    "dataset_active_sentences = pd.read_csv('../data/active_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ac114e86edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_for_underscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mquiet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m# of this loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mlast_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decisions to be made:\n",
    "    # Which variables to keep?\n",
    "    # Which features need to be constructed from the available variables?\n",
    "    # How do we want to deal with missings?\n",
    "        # e.g. impute? choose majority? some notes here: https://towardsdatascience.com/working-with-missing-data-in-machine-learning-9c0a430df4ce\n",
    "        \n",
    "# A first pass, following this group: https://bucklerd.github.io/MUSA801_Recidivism_Markdown/#\n",
    "    # Race - keep\n",
    "    # Sex - keep\n",
    "    # Age at each sentence - need to calculate using birth date and effective sentence begin date - more indifferent\n",
    "    # Age category each sentence - keep, look at literature to decide how to categorize\n",
    "    # Ethnicity - keep\n",
    "    # Citizenship - keep, but just look at variation, don't include in model\n",
    "    # Age at first incarceration? Could compute as age at first sentence - keep, similar information to age category\n",
    "    # Most serious current offense (since there are so many categories, do we want to map on our coded 5 point scale\n",
    "        # to this..?)\n",
    "        # - different versions of this (most serious offense, and turn everything else to other), one-hot encoding\n",
    "        # - with 5 point scale \n",
    "    # Current crime violent or not violent (not sure where they are gtting this from, or if its self constructed)\n",
    "        # - our scale 4-5 to 1, our scale 1-3 is 0 (self-constructed)\n",
    "        # - feel iffy about this, so also try leaving out\n",
    "    # Total sentence count - can be computed - lots of bias baked in? - would be at the individual level?\n",
    "        # - keep, and see how it affects the model (prior history context)\n",
    "    # Juvenile Offense Flag - would need to construct using age at first incarceration - keep\n",
    "    # total count of felony and misdemeanor charges - i think these can be calculated from sentence component\n",
    "        # would be at the individual level not sentence level? \n",
    "        # - keep, for the sentence that got a recidivate flag, how many flags in either category\n",
    "    # custody_class_code - i think this CONTROL_STATUS\n",
    "        # individual level not sentence level - don't keep (probably adds more bias than value...)\n",
    "    # special characteristics - i didn't really know how to make sense of this, so i didn't include it for now...\n",
    "    # - - don't keep (probably adds more bias than value...)\n",
    "    # total disciplinary infractions - would be at the individual level not the sentence level\n",
    "        # although this comes from a file that has infraction by date so in theory\n",
    "        #   we could calculate at the sentence level with some SQL maneouvering \n",
    "        # how many infractions between each start/end date of the sentence, but this would be a bit more complicated\n",
    "    # Type of last inmate movement - we have this, but i'm not sure how much value it adds. also its at the\n",
    "        # offender level, not sentence level - don't keep \n",
    "    \n",
    "\n",
    "# Thoughts on missingness:\n",
    "    # Race, Sex, Birth date - basically not missing, can drop or impute couple that are\n",
    "    # Ethnicity and Citizenship - Majority impute?\n",
    "    # Most serious current offense - already working on trying to make this less missing\n",
    "    # Disciplinary infractions - the way this is constructed is by merging on from a file that contains\n",
    "        # infractions. So i think it is safe to assume that if this variable is missing for an individual,\n",
    "        # they did not commit any infractions. replace with 0?\n",
    "    # \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions:\n",
    "\n",
    "*First model is most parsimonious\n",
    "* Bring in median household income and unemployment data so the predictor mechanism isn't just on individual (maybe NC, annual)\n",
    "\n",
    "### Splitting the work:\n",
    "* Damini: (pulling via SQL)\n",
    "    - Disciplinary infractions\n",
    "    - Most serious current offense\n",
    "    - Current crime violent\n",
    "    - Total count of felony and misdemeanor charges\n",
    "    - Total sentence count\n",
    "    \n",
    "* Charmaine:\n",
    "    - Median HH income\n",
    "    - Unemployment\n",
    "    - Age at each sentence - need to calculate using birth date and effective sentence begin date - more indifferent\n",
    "    - Age category each sentence - keep, look at literature to decide how to categorize\n",
    "    - Age at first incarceration? Could compute as age at first sentence - keep, similar information to age category\n",
    "    - Juvenile Offense Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charmaine's WIP code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many observations you have and make sure you don't drop any while creating new features\n",
    "dataset_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AGE_AT_SENTENCE\n",
    "dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'] = pd.to_datetime(dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'], yearfirst=True)\n",
    "dataset_main.loc[dataset_main['BIRTH_DATE'] == '0001-01-01', 'BIRTH_DATE'] = np.NaN\n",
    "dataset_main['BIRTH_DATE'] = pd.to_datetime(dataset_main['BIRTH_DATE'], format='%Y/%m/%d')\n",
    "\n",
    "dataset_main['age_at_sentence'] = (dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'] - dataset_main['BIRTH_DATE']).astype('<m8[Y]')\n",
    "dataset_main['age_at_sentence'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of misisng\n",
    "dataset_main['age_at_sentence'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check observations where age is negative\n",
    "dataset_main.loc[dataset_main['age_at_sentence'] < 0, ['EARLIEST_SENTENCE_EFFECTIVE_DT', 'BIRTH_DATE']]\n",
    "\n",
    "# Convert to NaN?\n",
    "dataset_main.loc[dataset_main['age_at_sentence'] < 0, ['age_at_sentence']] = np.NaN\n",
    "\n",
    "# Check number of missing\n",
    "dataset_main['age_at_sentence'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age categories\n",
    "# Resources: https://www.ussc.gov/research/research-reports/effects-aging-recidivism-among-federal-offenders\n",
    "dataset_main['age_cat'] = pd.cut(dataset_main['age_at_sentence'],\n",
    "                                 bins=[0,17,21,24,29,34,39,44,49,54,59,64,90],\n",
    "                                 labels=['Under 18', '18-21','22-24','25-29','30-34','35-39','40-44','45-49',\n",
    "                                        '50-54','55-59','60-64','65 and older',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main.groupby(['age_cat']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute age at first incarceration\n",
    "first_incarceration = pd.DataFrame(dataset_main.groupby(['ID'])['EARLIEST_SENTENCE_EFFECTIVE_DT'].min().reset_index(name='first_incarceration_date'))\n",
    "dataset_main = dataset_main.merge(first_incarceration, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main[['ID','COMMITMENT_PREFIX','EARLIEST_SENTENCE_EFFECTIVE_DT','first_incarceration_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for juvenile offense\n",
    "dataset_main['age_first_offense'] = (dataset_main['first_incarceration_date'] - dataset_main['BIRTH_DATE']).astype('<m8[Y]')\n",
    "dataset_main['age_first_offense'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check observations where age is negative\n",
    "dataset_main.loc[dataset_main['age_first_offense'] < 0, ['EARLIEST_SENTENCE_EFFECTIVE_DT', 'BIRTH_DATE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_main[dataset_main['age_first_offense'] < 10].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "\n",
    "dataset_main.hist(column=['age_first_offense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main[dataset_main['age_first_offense'] > 0].hist(column=['age_first_offense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NaN?\n",
    "dataset_main.loc[dataset_main['age_first_offense'] < 0, ['age_first_offense']] = np.NaN\n",
    "\n",
    "# Check number of misisng\n",
    "dataset_main['age_first_offense'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main['juv_first_offense'] = (dataset_main['age_first_offense'] < 18)\n",
    "dataset_main.sort_values('age_first_offense')[['BIRTH_DATE','first_incarceration_date','age_first_offense', 'juv_first_offense']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DISCUSS\n",
    "A lot of these dates don't make sense. How can a toddler be sentenced?\n",
    "\n",
    "* Replace with NaN if below 10 (talked with Damini about this)\n",
    "* Maybe impute to mean/median eventually.\n",
    "* We could trim the data to start at 1976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main.sort_values('age_first_offense')[['BIRTH_DATE','first_incarceration_date','age_first_offense', 'juv_first_offense']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in unemployment data\n",
    "* Source: BLS LAUS\n",
    "* Link: https://beta.bls.gov/dataViewer/view/timeseries/LASST370000000000003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main.groupby([dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'].dt.year]).size().plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earliest data BLS has only goes to 1976...\n",
    "### TO DISCUSS\n",
    "Should we restrict our data to 1976? We would end up dropping 5% of our data. \n",
    "\n",
    "Or 1984? (see median HH income data limitations below...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import downloaded CSV\n",
    "unemployment = pd.read_csv('../data/unemployment_nc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['month'] = unemployment['Period'].str[1:]\n",
    "unemployment['Year'] = unemployment['Year'].astype(str)\n",
    "unemployment['date_to_merge'] = unemployment['Year'].str.cat(unemployment['month'], sep =\"-\")\n",
    "unemployment['date_to_merge'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a str column to merge on\n",
    "dataset_main['date_to_merge'] = dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Rename variables \n",
    "unemployment = unemployment.rename(columns={\"Value\": \"unemp_rate\"})\n",
    "unemployment_limited = unemployment[['date_to_merge','unemp_rate']]\n",
    "\n",
    "# Merge with unemployment data\n",
    "dataset_main = dataset_main.merge(unemployment_limited, on='date_to_merge', how='left')\n",
    "check_cols = ['EARLIEST_SENTENCE_EFFECTIVE_DT','date_to_merge','unemp_rate']\n",
    "dataset_main[check_cols].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many are missing\n",
    "dataset_main['unemp_rate'].isnull().sum() / dataset_main.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in median household income\n",
    "* Source: Table H-8\n",
    "* Links: \n",
    "  * https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html\n",
    "  * https://fred.stlouisfed.org/series/MEHOINUSA672N\n",
    "* Note: Only has 1984-2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_inc = pd.read_excel('../data/h08.xls', sheet_name='edited', usecols=['Year','Median HH Income'], nrows=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source: https://www.census.gov/topics/income-poverty/income/guidance/cps-historic-footnotes.html\n",
    "\n",
    "36.\tBeginning with 2009 income data, the Census Bureau expanded the upper income interval used to calculate medians and Gini indexes to \\\\$250,000 or more. Medians falling in the upper open-ended interval are plugged with \"\\\\$250,000.\" Before 2009, the upper open-ended interval was \\\\$100,000 and a plug of \"\\\\$100,000\" was used.\n",
    "\n",
    "37.\tImplementation of Census 2010-based population controls.\n",
    "\n",
    "38.\tThe 2014 CPS ASEC included redesigned questions for income and health insurance coverage. All of the approximately 98,000 addresses were eligible to receive the redesigned set of health insurance coverage questions. The redesigned income questions were implemented to a subsample of the 98,000 addresses using a probability split panel design. Approximately 68,000 addresses were eligible to receive a set of income questions similar to those used in the 2013 CPS ASEC and the remaining 30,000 addresses were eligible to receive the redesigned income questions. The source of these 2013 estimates is the portion of the CPS ASEC sample which received the income questions consistent with the 2013 CPS ASEC, approximately 68,000 addresses.\n",
    "\n",
    "39.\tThe source of these 2013 estimates is the portion of the CPS ASEC sample which received the redesigned income questions, approximately 30,000 addresses.\n",
    "\n",
    "40.\tImplementation of an updated CPS ASEC processing system.\n",
    "\n",
    "We have duplicates of 2013 and 2017, so footnotes 38, 39, and 40 are the most relevant. \n",
    "\n",
    "#### Decision: Which duplicates do we use?\n",
    "- Should we drop the (40) version of 2017? And use the updated version? \n",
    "- Should we drop the (39) version of 2013? To be consistent with the decision above to use the updated system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows and convert to string\n",
    "hh_inc_edit = hh_inc.copy()\n",
    "hh_inc_edit['Year'] = hh_inc_edit['Year'].astype(str)\n",
    "hh_inc_edit = hh_inc_edit.drop(axis=0, index=[2,6]) # Drop (39) and (40) versions of 2013 and 2017\n",
    "\n",
    "# Slice string to only keep numbers\n",
    "hh_inc_edit['Year'] = hh_inc_edit['Year'].str[:4]\n",
    "hh_inc_edit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a str column to merge on\n",
    "dataset_main['year_to_merge'] = dataset_main['EARLIEST_SENTENCE_EFFECTIVE_DT'].dt.strftime('%Y')\n",
    "\n",
    "# Rename variable\n",
    "hh_inc_edit = hh_inc_edit.rename(columns={\"Year\": \"year_to_merge\"})\n",
    "\n",
    "# Merge with dataset_main\n",
    "dataset_main = dataset_main.merge(hh_inc_edit, on='year_to_merge', how='left')\n",
    "check_cols = ['EARLIEST_SENTENCE_EFFECTIVE_DT','year_to_merge','Median HH Income']\n",
    "dataset_main[check_cols].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop merging variables\n",
    "dataset_main.drop(axis=1, columns=['year_to_merge', 'date_to_merge'], inplace=True)\n",
    "dataset_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Steps\n",
    "\n",
    "1. **Read Data.**\n",
    "Load the data. Your function for reading in data can be as simple as calling pd.read_csv. If this step is more complicated (e.g. in your projects), you will want to write more detailed functions.\n",
    "\n",
    "2. **Explore Data.**\n",
    "Automate common exploratory tasks. This can include generating distributions of variables, correlations between them, identifying outliers, summarizing by groups, identifying the time range of the data, etc. Feel free to leverage your work from previous labs and Step 1 above.\n",
    "\n",
    "3. **Create Training and Testing Sets.**\n",
    "Create training and testing splits. You should use a separate training set, validation set (to tune hyperparameters), and testing set to perform cross-validation.\n",
    "\n",
    "4. **Pre-Process Data.**\n",
    "Automate pre-processing steps. One function should impute missing values of continuous variables using the median value and the other should normalize continuous variables.\n",
    "    * No need to impute BIRTH_DATE, but we can impute AGE variables with median\n",
    "    * Majority-vote for juvenile flag\n",
    "    * Disciplinary infractions\n",
    "        * Missing should be converted to 0\n",
    "    * Most serious current offense - should not be missing\n",
    "        * Limit to certain number categories (e.g., top vs other), before train/test/split becuase not imputing.\n",
    "        * For version where we map on our scales, will be missing 5% of the time, imputed with most common category after train/test/split\n",
    "    * Current crime violent - will be missing in places\n",
    "        * Will either be missing or will be in our scale\n",
    "        * Impute with most common after train/test split \n",
    "    * Total count of felony and misdemeanor charges - might be missing\n",
    "        * Impute with median after train/test/split\n",
    "    * Total sentence count - shouldn't be missing \n",
    "\n",
    "\n",
    "5. **Generate Features.**\n",
    "Faciliate feature generation. One function should perform one-hot encoding of categorical variables (e.g. with pd.get_dummies) and one function should discretize continuous variables (e.g. with pd.cut). Discretizing continuous variables can be useful in cases where the variable has a significant cutoff value (for example, age could be discretized to distinguish between children under 18 and adults 18 and older).\n",
    "\n",
    "6. **Build Classifiers.**\n",
    "Apply machine learning models to a dataset. The function should also print the amount of time required to train each model. \n",
    "\n",
    "7. **Evaluate Classifiers.**\n",
    "Calculate the accuracy of your models based on your testing set, and validate models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damini's WIP Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daminisharma/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (20,21,22,29,30,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset_main_active = pd.read_csv('../data/dataset_main_active.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary until re run build data\n",
    "dataset_main_active.loc[dataset_main_active['NextPrefix']==0,'NextPrefix'] = \"NONE\"\n",
    "dataset_main_active.loc[dataset_main_active['NextPrefix']==\"0\",'NextPrefix'] = \"NONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                      int64\n",
       "COMMITMENT_PREFIX                      object\n",
       "EARLIEST_SENTENCE_EFFECTIVE_DT         object\n",
       "MOST_SERIOUS_OFFENSE_CODE              object\n",
       "INMATE_COMPUTATION_STATUS_FLAG         object\n",
       "END_DATE                               object\n",
       "PROJ_END_DATE                          object\n",
       "INMATE_RECORD_STATUS_CODE              object\n",
       "INMATE_ADMIN_STATUS_CODE               object\n",
       "DATE_OF_LAST_INMATE_MOVEMENT           object\n",
       "TYPE_OF_LAST_INMATE_MOVEMENT           object\n",
       "CURRENT_COMMITMENT_PREFIX              object\n",
       "CONTROL_STATUS                         object\n",
       "GENDER                                 object\n",
       "RACE                                   object\n",
       "BIRTH_DATE                             object\n",
       "STATE_BORN                             object\n",
       "ETHNICITY                              object\n",
       "CITIZENSHIP                            object\n",
       "PRIMARY_OFFENSE_CODE                   object\n",
       "NextPrefix                             object\n",
       "NextStart                              object\n",
       "NextOffense                            object\n",
       "new_col                                 int64\n",
       "Time_Diff                             float64\n",
       "Recidivate                            float64\n",
       "INFRACTION_PER_SENT                   float64\n",
       "('Count', 'FELON')                    float64\n",
       "('Count', 'MISD.')                    float64\n",
       "Primary offense code_x                 object\n",
       "Description (if needed)_x              object\n",
       "Recidivate_Risk_Level                 float64\n",
       "Needed a check?_x                      object\n",
       "Recidivate_Risk_Level_Lenient         float64\n",
       "Recidivate_Risk_Level_Harsh           float64\n",
       "Primary offense code_y                 object\n",
       "Description (if needed)_y              object\n",
       "Current_Offense_Risk_Level            float64\n",
       "Needed a check?_y                      object\n",
       "Current_Offense_Risk_Level_Lenient    float64\n",
       "Current_Offense_Risk_Level_Harsh      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_main_active.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main_active.rename(columns={\"('Count', 'FELON')\":'felon_count',\"('Count', 'MISD.')\":'misd_count'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'COMMITMENT_PREFIX', 'EARLIEST_SENTENCE_EFFECTIVE_DT',\n",
       "       'MOST_SERIOUS_OFFENSE_CODE', 'INMATE_COMPUTATION_STATUS_FLAG',\n",
       "       'END_DATE', 'PROJ_END_DATE', 'INMATE_RECORD_STATUS_CODE',\n",
       "       'INMATE_ADMIN_STATUS_CODE', 'DATE_OF_LAST_INMATE_MOVEMENT',\n",
       "       'TYPE_OF_LAST_INMATE_MOVEMENT', 'CURRENT_COMMITMENT_PREFIX',\n",
       "       'CONTROL_STATUS', 'GENDER', 'RACE', 'BIRTH_DATE', 'STATE_BORN',\n",
       "       'ETHNICITY', 'CITIZENSHIP', 'PRIMARY_OFFENSE_CODE', 'NextPrefix',\n",
       "       'NextStart', 'NextOffense', 'new_col', 'Time_Diff', 'Recidivate',\n",
       "       'INFRACTION_PER_SENT', 'felon_count', 'misd_count',\n",
       "       'Primary offense code_x', 'Description (if needed)_x',\n",
       "       'Recidivate_Risk_Level', 'Needed a check?_x',\n",
       "       'Recidivate_Risk_Level_Lenient', 'Recidivate_Risk_Level_Harsh',\n",
       "       'Primary offense code_y', 'Description (if needed)_y',\n",
       "       'Current_Offense_Risk_Level', 'Needed a check?_y',\n",
       "       'Current_Offense_Risk_Level_Lenient',\n",
       "       'Current_Offense_Risk_Level_Harsh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_main_active.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_main_active = dataset_main_active.loc[:,['ID', 'COMMITMENT_PREFIX', 'EARLIEST_SENTENCE_EFFECTIVE_DT','MOST_SERIOUS_OFFENSE_CODE','END_DATE', 'INMATE_RECORD_STATUS_CODE','INMATE_ADMIN_STATUS_CODE', 'DATE_OF_LAST_INMATE_MOVEMENT','TYPE_OF_LAST_INMATE_MOVEMENT','CONTROL_STATUS', 'GENDER', 'RACE', 'BIRTH_DATE', 'STATE_BORN','ETHNICITY', 'CITIZENSHIP', 'PRIMARY_OFFENSE_CODE', 'NextPrefix','NextStart', 'NextOffense', 'Time_Diff', 'Recidivate','INFRACTION_PER_SENT', 'misd_count','felon_count','Recidivate_Risk_Level', 'Recidivate_Risk_Level_Lenient', 'Recidivate_Risk_Level_Harsh','Current_Offense_Risk_Level','Current_Offense_Risk_Level_Lenient','Current_Offense_Risk_Level_Harsh']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMITMENT_PREFIX</th>\n",
       "      <th>EARLIEST_SENTENCE_EFFECTIVE_DT</th>\n",
       "      <th>MOST_SERIOUS_OFFENSE_CODE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>INMATE_RECORD_STATUS_CODE</th>\n",
       "      <th>INMATE_ADMIN_STATUS_CODE</th>\n",
       "      <th>DATE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>TYPE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>CONTROL_STATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE_BORN</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>CITIZENSHIP</th>\n",
       "      <th>PRIMARY_OFFENSE_CODE</th>\n",
       "      <th>NextPrefix</th>\n",
       "      <th>NextStart</th>\n",
       "      <th>NextOffense</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1983-07-12</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1961-10-15</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>AA</td>\n",
       "      <td>1973-01-30</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1973-03-28</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>AA</td>\n",
       "      <td>1990-04-09</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1995-09-14</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1963-12-29</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>AB</td>\n",
       "      <td>1993-08-30</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>AB</td>\n",
       "      <td>1993-08-30</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1994-01-26</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1995-09-14</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1963-12-29</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>BA</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID COMMITMENT_PREFIX EARLIEST_SENTENCE_EFFECTIVE_DT  \\\n",
       "0   4                AA                     1983-07-12   \n",
       "1   6                AA                     1973-01-30   \n",
       "2   6                AB                     1973-04-11   \n",
       "3   8                AA                     1990-04-09   \n",
       "4   8                AB                     1993-08-30   \n",
       "\n",
       "    MOST_SERIOUS_OFFENSE_CODE    END_DATE INMATE_RECORD_STATUS_CODE  \\\n",
       "0            SELL SCHEDULE II  1984-07-11                  INACTIVE   \n",
       "1             WORTHLESS CHECK  1973-03-28                  INACTIVE   \n",
       "2             WORTHLESS CHECK  1975-08-18                  INACTIVE   \n",
       "3  DWI DRIVING WHILE IMPAIRED  1990-05-17                  INACTIVE   \n",
       "4   HABITUAL IMPAIRED DRIVING  1994-01-26                  INACTIVE   \n",
       "\n",
       "  INMATE_ADMIN_STATUS_CODE DATE_OF_LAST_INMATE_MOVEMENT  \\\n",
       "0                 INACTIVE                   1984-07-11   \n",
       "1                 INACTIVE                   1975-08-18   \n",
       "2                 INACTIVE                   1975-08-18   \n",
       "3                 INACTIVE                   1995-09-14   \n",
       "4                 INACTIVE                   1995-09-14   \n",
       "\n",
       "  TYPE_OF_LAST_INMATE_MOVEMENT                  CONTROL_STATUS GENDER   RACE  \\\n",
       "0            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "1            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "2            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "3            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "4            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "\n",
       "   BIRTH_DATE      STATE_BORN ETHNICITY   CITIZENSHIP  \\\n",
       "0  1961-10-15          ALASKA   UNKNOWN  BORN IN U.S.   \n",
       "1  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "2  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "3  1963-12-29  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "4  1963-12-29  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "\n",
       "         PRIMARY_OFFENSE_CODE NextPrefix   NextStart  \\\n",
       "0            SELL SCHEDULE II       NONE         NaN   \n",
       "1             WORTHLESS CHECK         AB  1973-04-11   \n",
       "2             WORTHLESS CHECK       NONE         NaN   \n",
       "3  DWI DRIVING WHILE IMPAIRED         AB  1993-08-30   \n",
       "4   HABITUAL IMPAIRED DRIVING         BA  1995-01-02   \n",
       "\n",
       "                 NextOffense  Time_Diff  Recidivate  INFRACTION_PER_SENT  \\\n",
       "0                          0        NaN         0.0                  0.0   \n",
       "1            WORTHLESS CHECK        0.0         1.0                  0.0   \n",
       "2                          0        NaN         0.0                  0.0   \n",
       "3  HABITUAL IMPAIRED DRIVING        3.0         0.0                  0.0   \n",
       "4  HABITUAL IMPAIRED DRIVING        1.0         1.0                  0.0   \n",
       "\n",
       "   misd_count  felon_count  Recidivate_Risk_Level  \\\n",
       "0         0.0          2.0                    0.0   \n",
       "1         1.0          0.0                    1.0   \n",
       "2        27.0          0.0                    0.0   \n",
       "3         1.0          0.0                    0.0   \n",
       "4         0.0          1.0                    3.0   \n",
       "\n",
       "   Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            1.0                          1.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            3.0                          3.0   \n",
       "\n",
       "   Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "0                         3.0                                 2.0   \n",
       "1                         1.0                                 1.0   \n",
       "2                         1.0                                 1.0   \n",
       "3                         2.0                                 2.0   \n",
       "4                         3.0                                 3.0   \n",
       "\n",
       "   Current_Offense_Risk_Level_Harsh  \n",
       "0                               4.0  \n",
       "1                               1.0  \n",
       "2                               1.0  \n",
       "3                               2.0  \n",
       "4                               3.0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_main_active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow for features:\n",
    "    - Stage 0: constructing variables, understanding weirdness and outliers\n",
    "    - Stage 1: train/test/validate/active split\n",
    "    - Stage 2: pre-process - including imputing messiness for vars created in Stage 0, and creating variables based on those (e.g. once Age has been imputed, construct Age_cat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disciplinary infractions\n",
    "- Stage 0: constructed in build_dataset, missings replaced with 0 - no infractions assumed if ID not found in   infractions dataset\n",
    "- Stage 2: Normalization of continuous var required\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most serious current offense\n",
    "- Stage 0 (v1): Construct more generalized var which captures X% of offenses, turning all else to others\n",
    "- Stage 2 (v1): There should be no missingness (double check this) - will need one-hot encoding\n",
    "    \n",
    "- Stage 0 (v2): (alt var - scale coded by us): Already merged, nothing further needed\n",
    "- Stage 2 (v2): there will be missings (since we only coded 95% of offenses) so fill NA with majority then one-hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most serious current offense v1\n",
    "#most_offenses = dataset_main_active.groupby(\"MOST_SERIOUS_OFFENSE_CODE\").size().reset_index(name=\"count\")\n",
    "most_offenses = dataset_main_active.groupby(\"MOST_SERIOUS_OFFENSE_CODE\")['ID'].size().reset_index(name=\"count\")\n",
    "most_offenses['PCT'] = most_offenses['count'] / dataset_main_active.shape[0]\n",
    "most_offenses = most_offenses.sort_values(by='PCT', ascending=False)\n",
    "most_offenses['CUMSUM'] = most_offenses['PCT'].cumsum()\n",
    "\n",
    "most_offenses['OFFENSE_CLEAN'] = most_offenses['MOST_SERIOUS_OFFENSE_CODE']\n",
    "most_offenses.loc[most_offenses['CUMSUM'] > 0.9,'OFFENSE_CLEAN'] = \"OTHER\"\n",
    "most_offenses = most_offenses.loc[:,['MOST_SERIOUS_OFFENSE_CODE','OFFENSE_CLEAN']]\n",
    "\n",
    "# Merge this back onto main dataset\n",
    "dataset_main_active = dataset_main_active.merge(most_offenses, how=\"left\", on=\"MOST_SERIOUS_OFFENSE_CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMITMENT_PREFIX</th>\n",
       "      <th>EARLIEST_SENTENCE_EFFECTIVE_DT</th>\n",
       "      <th>MOST_SERIOUS_OFFENSE_CODE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>INMATE_RECORD_STATUS_CODE</th>\n",
       "      <th>INMATE_ADMIN_STATUS_CODE</th>\n",
       "      <th>DATE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>TYPE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>CONTROL_STATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE_BORN</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>CITIZENSHIP</th>\n",
       "      <th>PRIMARY_OFFENSE_CODE</th>\n",
       "      <th>NextPrefix</th>\n",
       "      <th>NextStart</th>\n",
       "      <th>NextOffense</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>OFFENSE_CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1983-07-12</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1961-10-15</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>AA</td>\n",
       "      <td>1973-01-30</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1973-03-28</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>AA</td>\n",
       "      <td>1990-04-09</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1995-09-14</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1963-12-29</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>AB</td>\n",
       "      <td>1993-08-30</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>AB</td>\n",
       "      <td>1993-08-30</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1994-01-26</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1995-09-14</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1963-12-29</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>BA</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID COMMITMENT_PREFIX EARLIEST_SENTENCE_EFFECTIVE_DT  \\\n",
       "0   4                AA                     1983-07-12   \n",
       "1   6                AA                     1973-01-30   \n",
       "2   6                AB                     1973-04-11   \n",
       "3   8                AA                     1990-04-09   \n",
       "4   8                AB                     1993-08-30   \n",
       "\n",
       "    MOST_SERIOUS_OFFENSE_CODE    END_DATE INMATE_RECORD_STATUS_CODE  \\\n",
       "0            SELL SCHEDULE II  1984-07-11                  INACTIVE   \n",
       "1             WORTHLESS CHECK  1973-03-28                  INACTIVE   \n",
       "2             WORTHLESS CHECK  1975-08-18                  INACTIVE   \n",
       "3  DWI DRIVING WHILE IMPAIRED  1990-05-17                  INACTIVE   \n",
       "4   HABITUAL IMPAIRED DRIVING  1994-01-26                  INACTIVE   \n",
       "\n",
       "  INMATE_ADMIN_STATUS_CODE DATE_OF_LAST_INMATE_MOVEMENT  \\\n",
       "0                 INACTIVE                   1984-07-11   \n",
       "1                 INACTIVE                   1975-08-18   \n",
       "2                 INACTIVE                   1975-08-18   \n",
       "3                 INACTIVE                   1995-09-14   \n",
       "4                 INACTIVE                   1995-09-14   \n",
       "\n",
       "  TYPE_OF_LAST_INMATE_MOVEMENT                  CONTROL_STATUS GENDER   RACE  \\\n",
       "0            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "1            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "2            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "3            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "4            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "\n",
       "   BIRTH_DATE      STATE_BORN ETHNICITY   CITIZENSHIP  \\\n",
       "0  1961-10-15          ALASKA   UNKNOWN  BORN IN U.S.   \n",
       "1  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "2  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "3  1963-12-29  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "4  1963-12-29  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "\n",
       "         PRIMARY_OFFENSE_CODE NextPrefix   NextStart  \\\n",
       "0            SELL SCHEDULE II       NONE         NaN   \n",
       "1             WORTHLESS CHECK         AB  1973-04-11   \n",
       "2             WORTHLESS CHECK       NONE         NaN   \n",
       "3  DWI DRIVING WHILE IMPAIRED         AB  1993-08-30   \n",
       "4   HABITUAL IMPAIRED DRIVING         BA  1995-01-02   \n",
       "\n",
       "                 NextOffense  Time_Diff  Recidivate  INFRACTION_PER_SENT  \\\n",
       "0                          0        NaN         0.0                  0.0   \n",
       "1            WORTHLESS CHECK        0.0         1.0                  0.0   \n",
       "2                          0        NaN         0.0                  0.0   \n",
       "3  HABITUAL IMPAIRED DRIVING        3.0         0.0                  0.0   \n",
       "4  HABITUAL IMPAIRED DRIVING        1.0         1.0                  0.0   \n",
       "\n",
       "   misd_count  felon_count  Recidivate_Risk_Level  \\\n",
       "0         0.0          2.0                    0.0   \n",
       "1         1.0          0.0                    1.0   \n",
       "2        27.0          0.0                    0.0   \n",
       "3         1.0          0.0                    0.0   \n",
       "4         0.0          1.0                    3.0   \n",
       "\n",
       "   Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            1.0                          1.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            3.0                          3.0   \n",
       "\n",
       "   Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "0                         3.0                                 2.0   \n",
       "1                         1.0                                 1.0   \n",
       "2                         1.0                                 1.0   \n",
       "3                         2.0                                 2.0   \n",
       "4                         3.0                                 3.0   \n",
       "\n",
       "   Current_Offense_Risk_Level_Harsh               OFFENSE_CLEAN  \n",
       "0                               4.0            SELL SCHEDULE II  \n",
       "1                               1.0             WORTHLESS CHECK  \n",
       "2                               1.0             WORTHLESS CHECK  \n",
       "3                               2.0  DWI DRIVING WHILE IMPAIRED  \n",
       "4                               3.0   HABITUAL IMPAIRED DRIVING  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_main_active.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Crime Violent Flag\n",
    "- Stage 0 (v1): don't include variable (we dont have it)\n",
    "- Stage 2 (v1): dont include variable (we dont have it)\n",
    "    \n",
    "- Stage 0 (v2 - scale coded by us): Already merged, nothing further needed\n",
    "- Stage 2: there will be missings (since we only coded 95% of offenses) so fill NA with majority then categorize as 1 for receiving score 4 or 5 and 0 otherwise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total count of felony and misdemeanor charges\n",
    "- Stage 0: merged and created, nothing further needed\n",
    "- Stage 2: impute NAs with median (very few missing) then normalize since continuous var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total sentence count\n",
    "- Stage 0: construct\n",
    "- Stage 2: shouldnt be missing (check) - then normalize since continuous var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = dataset_main_active.groupby(['ID','COMMITMENT_PREFIX']).count().groupby(level=0).cumsum().reset_index()\n",
    "count['sentence_count'] = count['EARLIEST_SENTENCE_EFFECTIVE_DT'] - 1\n",
    "count = count.loc[:,['ID','COMMITMENT_PREFIX','sentence_count']]\n",
    "dataset_main_active = dataset_main_active.merge(count, how=\"left\", on = ['ID','COMMITMENT_PREFIX'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMITMENT_PREFIX</th>\n",
       "      <th>EARLIEST_SENTENCE_EFFECTIVE_DT</th>\n",
       "      <th>MOST_SERIOUS_OFFENSE_CODE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>INMATE_RECORD_STATUS_CODE</th>\n",
       "      <th>INMATE_ADMIN_STATUS_CODE</th>\n",
       "      <th>DATE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>TYPE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>CONTROL_STATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE_BORN</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>CITIZENSHIP</th>\n",
       "      <th>PRIMARY_OFFENSE_CODE</th>\n",
       "      <th>NextPrefix</th>\n",
       "      <th>NextStart</th>\n",
       "      <th>NextOffense</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>OFFENSE_CLEAN</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1983-07-12</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1961-10-15</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>AA</td>\n",
       "      <td>1973-01-30</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1973-03-28</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>AA</td>\n",
       "      <td>1990-04-09</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1995-09-14</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1963-12-29</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>AB</td>\n",
       "      <td>1993-08-30</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DWI DRIVING WHILE IMPAIRED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>AB</td>\n",
       "      <td>1993-08-30</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1994-01-26</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1995-09-14</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1963-12-29</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>BA</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>HABITUAL IMPAIRED DRIVING</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID COMMITMENT_PREFIX EARLIEST_SENTENCE_EFFECTIVE_DT  \\\n",
       "0   4                AA                     1983-07-12   \n",
       "1   6                AA                     1973-01-30   \n",
       "2   6                AB                     1973-04-11   \n",
       "3   8                AA                     1990-04-09   \n",
       "4   8                AB                     1993-08-30   \n",
       "\n",
       "    MOST_SERIOUS_OFFENSE_CODE    END_DATE INMATE_RECORD_STATUS_CODE  \\\n",
       "0            SELL SCHEDULE II  1984-07-11                  INACTIVE   \n",
       "1             WORTHLESS CHECK  1973-03-28                  INACTIVE   \n",
       "2             WORTHLESS CHECK  1975-08-18                  INACTIVE   \n",
       "3  DWI DRIVING WHILE IMPAIRED  1990-05-17                  INACTIVE   \n",
       "4   HABITUAL IMPAIRED DRIVING  1994-01-26                  INACTIVE   \n",
       "\n",
       "  INMATE_ADMIN_STATUS_CODE DATE_OF_LAST_INMATE_MOVEMENT  \\\n",
       "0                 INACTIVE                   1984-07-11   \n",
       "1                 INACTIVE                   1975-08-18   \n",
       "2                 INACTIVE                   1975-08-18   \n",
       "3                 INACTIVE                   1995-09-14   \n",
       "4                 INACTIVE                   1995-09-14   \n",
       "\n",
       "  TYPE_OF_LAST_INMATE_MOVEMENT                  CONTROL_STATUS GENDER   RACE  \\\n",
       "0            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "1            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "2            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "3            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "4            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "\n",
       "   BIRTH_DATE      STATE_BORN ETHNICITY   CITIZENSHIP  \\\n",
       "0  1961-10-15          ALASKA   UNKNOWN  BORN IN U.S.   \n",
       "1  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "2  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "3  1963-12-29  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "4  1963-12-29  NORTH CAROLINA   UNKNOWN  BORN IN U.S.   \n",
       "\n",
       "         PRIMARY_OFFENSE_CODE NextPrefix   NextStart  \\\n",
       "0            SELL SCHEDULE II       NONE         NaN   \n",
       "1             WORTHLESS CHECK         AB  1973-04-11   \n",
       "2             WORTHLESS CHECK       NONE         NaN   \n",
       "3  DWI DRIVING WHILE IMPAIRED         AB  1993-08-30   \n",
       "4   HABITUAL IMPAIRED DRIVING         BA  1995-01-02   \n",
       "\n",
       "                 NextOffense  Time_Diff  Recidivate  INFRACTION_PER_SENT  \\\n",
       "0                          0        NaN         0.0                  0.0   \n",
       "1            WORTHLESS CHECK        0.0         1.0                  0.0   \n",
       "2                          0        NaN         0.0                  0.0   \n",
       "3  HABITUAL IMPAIRED DRIVING        3.0         0.0                  0.0   \n",
       "4  HABITUAL IMPAIRED DRIVING        1.0         1.0                  0.0   \n",
       "\n",
       "   misd_count  felon_count  Recidivate_Risk_Level  \\\n",
       "0         0.0          2.0                    0.0   \n",
       "1         1.0          0.0                    1.0   \n",
       "2        27.0          0.0                    0.0   \n",
       "3         1.0          0.0                    0.0   \n",
       "4         0.0          1.0                    3.0   \n",
       "\n",
       "   Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            1.0                          1.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            3.0                          3.0   \n",
       "\n",
       "   Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "0                         3.0                                 2.0   \n",
       "1                         1.0                                 1.0   \n",
       "2                         1.0                                 1.0   \n",
       "3                         2.0                                 2.0   \n",
       "4                         3.0                                 3.0   \n",
       "\n",
       "   Current_Offense_Risk_Level_Harsh               OFFENSE_CLEAN  \\\n",
       "0                               4.0            SELL SCHEDULE II   \n",
       "1                               1.0             WORTHLESS CHECK   \n",
       "2                               1.0             WORTHLESS CHECK   \n",
       "3                               2.0  DWI DRIVING WHILE IMPAIRED   \n",
       "4                               3.0   HABITUAL IMPAIRED DRIVING   \n",
       "\n",
       "   sentence_count  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_main_active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                         0\n",
       "COMMITMENT_PREFIX                          0\n",
       "EARLIEST_SENTENCE_EFFECTIVE_DT             0\n",
       "MOST_SERIOUS_OFFENSE_CODE                  0\n",
       "END_DATE                                   0\n",
       "INMATE_RECORD_STATUS_CODE               5853\n",
       "INMATE_ADMIN_STATUS_CODE                5853\n",
       "DATE_OF_LAST_INMATE_MOVEMENT            5853\n",
       "TYPE_OF_LAST_INMATE_MOVEMENT           19702\n",
       "CONTROL_STATUS                          5853\n",
       "GENDER                                     0\n",
       "RACE                                       1\n",
       "BIRTH_DATE                                 0\n",
       "STATE_BORN                             30517\n",
       "ETHNICITY                                702\n",
       "CITIZENSHIP                              680\n",
       "PRIMARY_OFFENSE_CODE                   43502\n",
       "NextPrefix                                 0\n",
       "NextStart                             457099\n",
       "NextOffense                                0\n",
       "Time_Diff                             457099\n",
       "Recidivate                             32801\n",
       "INFRACTION_PER_SENT                        0\n",
       "misd_count                                43\n",
       "felon_count                               43\n",
       "Recidivate_Risk_Level                  32801\n",
       "Recidivate_Risk_Level_Lenient          32801\n",
       "Recidivate_Risk_Level_Harsh            32801\n",
       "Current_Offense_Risk_Level             46251\n",
       "Current_Offense_Risk_Level_Lenient     46251\n",
       "Current_Offense_Risk_Level_Harsh       46251\n",
       "OFFENSE_CLEAN                              0\n",
       "sentence_count                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_main_active.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps:\n",
    "- Train/test/validate/active split\n",
    "- Write functions to conduct stage 2 for the above vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling For Train Test Validate Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of active sentences dataset:  32801\n"
     ]
    }
   ],
   "source": [
    "# hold out active sentences\n",
    "active_sentences = dataset_main_active[(dataset_main_active['INMATE_ADMIN_STATUS_CODE']=='ACTIVE') & (dataset_main_active['NextPrefix']==\"NONE\") ]\n",
    "print(\"Size of active sentences dataset: \",active_sentences.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  821314\n"
     ]
    }
   ],
   "source": [
    "# Drop those missing decided category\n",
    "dataset_no_active = dataset_main_active[(dataset_main_active['Recidivate_Risk_Level'].notnull())]\n",
    "print(\"Dataset size: \" , dataset_no_active.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>COMMITMENT_PREFIX</th>\n",
       "      <th>EARLIEST_SENTENCE_EFFECTIVE_DT</th>\n",
       "      <th>MOST_SERIOUS_OFFENSE_CODE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>INMATE_RECORD_STATUS_CODE</th>\n",
       "      <th>INMATE_ADMIN_STATUS_CODE</th>\n",
       "      <th>DATE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>TYPE_OF_LAST_INMATE_MOVEMENT</th>\n",
       "      <th>CONTROL_STATUS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE_BORN</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>CITIZENSHIP</th>\n",
       "      <th>PRIMARY_OFFENSE_CODE</th>\n",
       "      <th>NextPrefix</th>\n",
       "      <th>NextStart</th>\n",
       "      <th>NextOffense</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>OFFENSE_CLEAN</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1983-07-12</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1984-07-11</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1961-10-15</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SELL SCHEDULE II</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>AA</td>\n",
       "      <td>1973-01-30</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>1973-03-28</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>1975-08-18</td>\n",
       "      <td>TERMINATED PAROLE</td>\n",
       "      <td>REGULAR POPULATION        RPOP</td>\n",
       "      <td>MALE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>1951-07-17</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>BORN IN U.S.</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>AB</td>\n",
       "      <td>1973-04-11</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WORTHLESS CHECK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID COMMITMENT_PREFIX EARLIEST_SENTENCE_EFFECTIVE_DT  \\\n",
       "0   4                AA                     1983-07-12   \n",
       "1   6                AA                     1973-01-30   \n",
       "\n",
       "  MOST_SERIOUS_OFFENSE_CODE    END_DATE INMATE_RECORD_STATUS_CODE  \\\n",
       "0          SELL SCHEDULE II  1984-07-11                  INACTIVE   \n",
       "1           WORTHLESS CHECK  1973-03-28                  INACTIVE   \n",
       "\n",
       "  INMATE_ADMIN_STATUS_CODE DATE_OF_LAST_INMATE_MOVEMENT  \\\n",
       "0                 INACTIVE                   1984-07-11   \n",
       "1                 INACTIVE                   1975-08-18   \n",
       "\n",
       "  TYPE_OF_LAST_INMATE_MOVEMENT                  CONTROL_STATUS GENDER   RACE  \\\n",
       "0            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "1            TERMINATED PAROLE  REGULAR POPULATION        RPOP   MALE  WHITE   \n",
       "\n",
       "   BIRTH_DATE      STATE_BORN ETHNICITY   CITIZENSHIP PRIMARY_OFFENSE_CODE  \\\n",
       "0  1961-10-15          ALASKA   UNKNOWN  BORN IN U.S.     SELL SCHEDULE II   \n",
       "1  1951-07-17  NORTH CAROLINA   UNKNOWN  BORN IN U.S.      WORTHLESS CHECK   \n",
       "\n",
       "  NextPrefix   NextStart      NextOffense  Time_Diff  Recidivate  \\\n",
       "0       NONE         NaN                0        NaN         0.0   \n",
       "1         AB  1973-04-11  WORTHLESS CHECK        0.0         1.0   \n",
       "\n",
       "   INFRACTION_PER_SENT  misd_count  felon_count  Recidivate_Risk_Level  \\\n",
       "0                  0.0         0.0          2.0                    0.0   \n",
       "1                  0.0         1.0          0.0                    1.0   \n",
       "\n",
       "   Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            1.0                          1.0   \n",
       "\n",
       "   Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "0                         3.0                                 2.0   \n",
       "1                         1.0                                 1.0   \n",
       "\n",
       "   Current_Offense_Risk_Level_Harsh     OFFENSE_CLEAN  sentence_count  \n",
       "0                               4.0  SELL SCHEDULE II               0  \n",
       "1                               1.0   WORTHLESS CHECK               0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_no_active.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdOut = 0.2\n",
    "randomState = 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_no_active = dataset_no_active_backup\n",
    "#dataset_no_active_backup = dataset_no_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0:00:03.815541\n"
     ]
    }
   ],
   "source": [
    "# Train, val, test split:\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "# get number of unique ids and the uniqe IDs\n",
    "n_ID = len(dataset_no_active.ID.unique())\n",
    "ids = pd.DataFrame(dataset_no_active.ID.unique())\n",
    "\n",
    "# sample from IDs\n",
    "train_index = ids.sample(round(n_ID*(1-holdOut)),random_state = randomState ).values.tolist()\n",
    "train_index = [item for sublist in train_index for item in sublist]\n",
    "# train data is data from any IDs that show up in train index\n",
    "train_val = dataset_no_active[dataset_no_active['ID'].isin(train_index)]\n",
    "# test data is data from any IDs that don't show up in train index\n",
    "test_data = dataset_no_active[~dataset_no_active['ID'].isin(train_index)]\n",
    "\n",
    "# repeat similar process for validate data\n",
    "n_ID = len(train_val.ID.unique())\n",
    "ids = pd.DataFrame(train_val.ID.unique())\n",
    "\n",
    "# sample from IDs\n",
    "train_index = ids.sample(round(n_ID*(1-holdOut)),random_state = randomState ).values.tolist()\n",
    "train_index = [item for sublist in train_index for item in sublist]\n",
    "# train data is data from any IDs that show up in train index\n",
    "train_data = train_val[train_val['ID'].isin(train_index)]\n",
    "# test data is data from any IDs that don't show up in train index\n",
    "validate_data = train_val[~train_val['ID'].isin(train_index)]\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "print(\"Time Elapsed:\", stop - start)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524854, 33)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164921, 33)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131539, 33)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique IDs: 444316\n",
      "Total Number of IDs in Test Data: 88863\n",
      "Total Number of IDs in Train Data: 284362\n",
      "Total Number of IDs in Validate Data: 71091\n",
      "Do the IDs add up? True\n",
      "Does Test Represent 20% of the data? False\n",
      "Test Represents X% of the data: 0.1999995498699124\n",
      "Does Train+Validate Represent 80% of the data? False\n",
      "Train+Validate Represents X% of the data: 0.8000004501300876\n",
      "Does Validate Represent 20% of the Train+Validate Data?: 0.2000011253245858\n",
      "Does Train Represent 20% of the Train+Validate Data?: 0.7999988746754142\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "print(\"Total Number of Unique IDs:\" , len(dataset_no_active.ID.unique()))\n",
    "print(\"Total Number of IDs in Test Data:\" , len(test_data.ID.unique()))\n",
    "print(\"Total Number of IDs in Train Data:\" , len(train_data.ID.unique()))\n",
    "print(\"Total Number of IDs in Validate Data:\" , len(validate_data.ID.unique()))\n",
    "\n",
    "print(\"Do the IDs add up?\" , len(test_data.ID.unique()) + len(train_data.ID.unique()) +  len(validate_data.ID.unique()) ==  len(dataset_no_active.ID.unique()))\n",
    "\n",
    "print(\"Does Test Represent 20% of the data?\", (len(test_data.ID.unique())/len(dataset_no_active.ID.unique())) == holdOut)\n",
    "print(\"Test Represents X% of the data:\", (len(test_data.ID.unique())/len(dataset_no_active.ID.unique())))\n",
    "print(\"Does Train+Validate Represent 80% of the data?\", len(train_data.ID.unique())+len(validate_data.ID.unique())/len(dataset_no_active.ID.unique()) == (1-holdOut))\n",
    "print(\"Train+Validate Represents X% of the data:\", (len(train_data.ID.unique())+len(validate_data.ID.unique()))/len(dataset_no_active.ID.unique()))\n",
    "print(\"Does Validate Represent 20% of the Train+Validate Data?:\", len(validate_data.ID.unique())/(len(train_data.ID.unique())+len(validate_data.ID.unique())))\n",
    "print(\"Does Train Represent 20% of the Train+Validate Data?:\", len(train_data.ID.unique())/(len(train_data.ID.unique())+len(validate_data.ID.unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.213140e+05</td>\n",
       "      <td>397016.000000</td>\n",
       "      <td>821314.000000</td>\n",
       "      <td>821314.000000</td>\n",
       "      <td>821271.000000</td>\n",
       "      <td>821271.000000</td>\n",
       "      <td>821314.000000</td>\n",
       "      <td>821314.000000</td>\n",
       "      <td>821314.000000</td>\n",
       "      <td>781307.000000</td>\n",
       "      <td>781307.000000</td>\n",
       "      <td>781307.000000</td>\n",
       "      <td>821314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.888432e+05</td>\n",
       "      <td>3.624128</td>\n",
       "      <td>0.171411</td>\n",
       "      <td>3.249752</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>1.011789</td>\n",
       "      <td>0.390327</td>\n",
       "      <td>0.323152</td>\n",
       "      <td>0.467961</td>\n",
       "      <td>2.313956</td>\n",
       "      <td>1.961114</td>\n",
       "      <td>2.723273</td>\n",
       "      <td>1.019291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.708854e+05</td>\n",
       "      <td>4.158104</td>\n",
       "      <td>0.376868</td>\n",
       "      <td>11.627107</td>\n",
       "      <td>1.548466</td>\n",
       "      <td>1.177446</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.814176</td>\n",
       "      <td>1.145918</td>\n",
       "      <td>1.064602</td>\n",
       "      <td>0.979385</td>\n",
       "      <td>1.214607</td>\n",
       "      <td>1.614028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>-265.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.989420e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.997460e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.042390e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.638741e+06</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      Time_Diff     Recidivate  INFRACTION_PER_SENT  \\\n",
       "count  8.213140e+05  397016.000000  821314.000000        821314.000000   \n",
       "mean   4.888432e+05       3.624128       0.171411             3.249752   \n",
       "std    3.708854e+05       4.158104       0.376868            11.627107   \n",
       "min    4.000000e+00    -265.000000       0.000000             0.000000   \n",
       "25%    1.989420e+05       1.000000       0.000000             0.000000   \n",
       "50%    3.997460e+05       2.000000       0.000000             0.000000   \n",
       "75%    7.042390e+05       5.000000       0.000000             2.000000   \n",
       "max    1.638741e+06      45.000000       1.000000          1009.000000   \n",
       "\n",
       "          misd_count    felon_count  Recidivate_Risk_Level  \\\n",
       "count  821271.000000  821271.000000          821314.000000   \n",
       "mean        0.873464       1.011789               0.390327   \n",
       "std         1.548466       1.177446               0.961667   \n",
       "min         0.000000       0.000000               0.000000   \n",
       "25%         0.000000       0.000000               0.000000   \n",
       "50%         0.000000       1.000000               0.000000   \n",
       "75%         1.000000       1.000000               0.000000   \n",
       "max       125.000000      78.000000               5.000000   \n",
       "\n",
       "       Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "count                  821314.000000                821314.000000   \n",
       "mean                        0.323152                     0.467961   \n",
       "std                         0.814176                     1.145918   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         0.000000                     0.000000   \n",
       "50%                         0.000000                     0.000000   \n",
       "75%                         0.000000                     0.000000   \n",
       "max                         5.000000                     5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "count               781307.000000                       781307.000000   \n",
       "mean                     2.313956                            1.961114   \n",
       "std                      1.064602                            0.979385   \n",
       "min                      1.000000                            1.000000   \n",
       "25%                      1.000000                            1.000000   \n",
       "50%                      2.000000                            2.000000   \n",
       "75%                      3.000000                            2.000000   \n",
       "max                      5.000000                            5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level_Harsh  sentence_count  \n",
       "count                     781307.000000   821314.000000  \n",
       "mean                           2.723273        1.019291  \n",
       "std                            1.214607        1.614028  \n",
       "min                            1.000000        0.000000  \n",
       "25%                            2.000000        0.000000  \n",
       "50%                            3.000000        0.000000  \n",
       "75%                            4.000000        1.000000  \n",
       "max                            5.000000       42.000000  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check #2 - how representative are our datasets compared to the overall dataset\n",
    "dataset_no_active.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.649210e+05</td>\n",
       "      <td>80157.000000</td>\n",
       "      <td>164921.000000</td>\n",
       "      <td>164921.000000</td>\n",
       "      <td>164907.000000</td>\n",
       "      <td>164907.000000</td>\n",
       "      <td>164921.000000</td>\n",
       "      <td>164921.000000</td>\n",
       "      <td>164921.000000</td>\n",
       "      <td>156790.000000</td>\n",
       "      <td>156790.000000</td>\n",
       "      <td>156790.000000</td>\n",
       "      <td>164921.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.890219e+05</td>\n",
       "      <td>3.621493</td>\n",
       "      <td>0.173404</td>\n",
       "      <td>3.298876</td>\n",
       "      <td>0.875797</td>\n",
       "      <td>1.009848</td>\n",
       "      <td>0.395165</td>\n",
       "      <td>0.326944</td>\n",
       "      <td>0.473784</td>\n",
       "      <td>2.307673</td>\n",
       "      <td>1.954168</td>\n",
       "      <td>2.718177</td>\n",
       "      <td>1.024588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.707744e+05</td>\n",
       "      <td>4.135034</td>\n",
       "      <td>0.378598</td>\n",
       "      <td>11.580602</td>\n",
       "      <td>1.530071</td>\n",
       "      <td>1.173411</td>\n",
       "      <td>0.967567</td>\n",
       "      <td>0.818879</td>\n",
       "      <td>1.152613</td>\n",
       "      <td>1.063567</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>1.215263</td>\n",
       "      <td>1.603956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.990360e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.997060e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.047590e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.638691e+06</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     Time_Diff     Recidivate  INFRACTION_PER_SENT  \\\n",
       "count  1.649210e+05  80157.000000  164921.000000        164921.000000   \n",
       "mean   4.890219e+05      3.621493       0.173404             3.298876   \n",
       "std    3.707744e+05      4.135034       0.378598            11.580602   \n",
       "min    6.000000e+00    -10.000000       0.000000             0.000000   \n",
       "25%    1.990360e+05      1.000000       0.000000             0.000000   \n",
       "50%    3.997060e+05      2.000000       0.000000             0.000000   \n",
       "75%    7.047590e+05      5.000000       0.000000             2.000000   \n",
       "max    1.638691e+06     42.000000       1.000000           590.000000   \n",
       "\n",
       "          misd_count    felon_count  Recidivate_Risk_Level  \\\n",
       "count  164907.000000  164907.000000          164921.000000   \n",
       "mean        0.875797       1.009848               0.395165   \n",
       "std         1.530071       1.173411               0.967567   \n",
       "min         0.000000       0.000000               0.000000   \n",
       "25%         0.000000       0.000000               0.000000   \n",
       "50%         0.000000       1.000000               0.000000   \n",
       "75%         1.000000       1.000000               0.000000   \n",
       "max        67.000000      48.000000               5.000000   \n",
       "\n",
       "       Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "count                  164921.000000                164921.000000   \n",
       "mean                        0.326944                     0.473784   \n",
       "std                         0.818879                     1.152613   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         0.000000                     0.000000   \n",
       "50%                         0.000000                     0.000000   \n",
       "75%                         0.000000                     0.000000   \n",
       "max                         5.000000                     5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "count               156790.000000                       156790.000000   \n",
       "mean                     2.307673                            1.954168   \n",
       "std                      1.063567                            0.977160   \n",
       "min                      1.000000                            1.000000   \n",
       "25%                      1.000000                            1.000000   \n",
       "50%                      2.000000                            2.000000   \n",
       "75%                      3.000000                            2.000000   \n",
       "max                      5.000000                            5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level_Harsh  sentence_count  \n",
       "count                     156790.000000   164921.000000  \n",
       "mean                           2.718177        1.024588  \n",
       "std                            1.215263        1.603956  \n",
       "min                            1.000000        0.000000  \n",
       "25%                            2.000000        0.000000  \n",
       "50%                            3.000000        0.000000  \n",
       "75%                            4.000000        1.000000  \n",
       "max                            5.000000       26.000000  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.248540e+05</td>\n",
       "      <td>253263.000000</td>\n",
       "      <td>524854.000000</td>\n",
       "      <td>524854.000000</td>\n",
       "      <td>524831.000000</td>\n",
       "      <td>524831.000000</td>\n",
       "      <td>524854.000000</td>\n",
       "      <td>524854.000000</td>\n",
       "      <td>524854.000000</td>\n",
       "      <td>499345.000000</td>\n",
       "      <td>499345.000000</td>\n",
       "      <td>499345.000000</td>\n",
       "      <td>524854.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.885718e+05</td>\n",
       "      <td>3.623846</td>\n",
       "      <td>0.170697</td>\n",
       "      <td>3.222081</td>\n",
       "      <td>0.871320</td>\n",
       "      <td>1.012600</td>\n",
       "      <td>0.388668</td>\n",
       "      <td>0.321973</td>\n",
       "      <td>0.465773</td>\n",
       "      <td>2.315545</td>\n",
       "      <td>1.962939</td>\n",
       "      <td>2.724609</td>\n",
       "      <td>1.017138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.709631e+05</td>\n",
       "      <td>4.168319</td>\n",
       "      <td>0.376244</td>\n",
       "      <td>11.542112</td>\n",
       "      <td>1.540026</td>\n",
       "      <td>1.182059</td>\n",
       "      <td>0.959678</td>\n",
       "      <td>0.813035</td>\n",
       "      <td>1.143334</td>\n",
       "      <td>1.064989</td>\n",
       "      <td>0.980260</td>\n",
       "      <td>1.214526</td>\n",
       "      <td>1.617431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>-265.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.986440e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.991775e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.040330e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.638741e+06</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      Time_Diff     Recidivate  INFRACTION_PER_SENT  \\\n",
       "count  5.248540e+05  253263.000000  524854.000000        524854.000000   \n",
       "mean   4.885718e+05       3.623846       0.170697             3.222081   \n",
       "std    3.709631e+05       4.168319       0.376244            11.542112   \n",
       "min    4.000000e+00    -265.000000       0.000000             0.000000   \n",
       "25%    1.986440e+05       1.000000       0.000000             0.000000   \n",
       "50%    3.991775e+05       2.000000       0.000000             0.000000   \n",
       "75%    7.040330e+05       5.000000       0.000000             2.000000   \n",
       "max    1.638741e+06      44.000000       1.000000          1009.000000   \n",
       "\n",
       "          misd_count    felon_count  Recidivate_Risk_Level  \\\n",
       "count  524831.000000  524831.000000          524854.000000   \n",
       "mean        0.871320       1.012600               0.388668   \n",
       "std         1.540026       1.182059               0.959678   \n",
       "min         0.000000       0.000000               0.000000   \n",
       "25%         0.000000       0.000000               0.000000   \n",
       "50%         0.000000       1.000000               0.000000   \n",
       "75%         1.000000       1.000000               0.000000   \n",
       "max       103.000000      78.000000               5.000000   \n",
       "\n",
       "       Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "count                  524854.000000                524854.000000   \n",
       "mean                        0.321973                     0.465773   \n",
       "std                         0.813035                     1.143334   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         0.000000                     0.000000   \n",
       "50%                         0.000000                     0.000000   \n",
       "75%                         0.000000                     0.000000   \n",
       "max                         5.000000                     5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "count               499345.000000                       499345.000000   \n",
       "mean                     2.315545                            1.962939   \n",
       "std                      1.064989                            0.980260   \n",
       "min                      1.000000                            1.000000   \n",
       "25%                      1.000000                            1.000000   \n",
       "50%                      2.000000                            2.000000   \n",
       "75%                      3.000000                            2.000000   \n",
       "max                      5.000000                            5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level_Harsh  sentence_count  \n",
       "count                     499345.000000   524854.000000  \n",
       "mean                           2.724609        1.017138  \n",
       "std                            1.214526        1.617431  \n",
       "min                            1.000000        0.000000  \n",
       "25%                            2.000000        0.000000  \n",
       "50%                            3.000000        0.000000  \n",
       "75%                            4.000000        1.000000  \n",
       "max                            5.000000       42.000000  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.315390e+05</td>\n",
       "      <td>63596.000000</td>\n",
       "      <td>131539.000000</td>\n",
       "      <td>131539.000000</td>\n",
       "      <td>131533.000000</td>\n",
       "      <td>131533.000000</td>\n",
       "      <td>131539.000000</td>\n",
       "      <td>131539.000000</td>\n",
       "      <td>131539.000000</td>\n",
       "      <td>125172.000000</td>\n",
       "      <td>125172.000000</td>\n",
       "      <td>125172.000000</td>\n",
       "      <td>131539.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.897019e+05</td>\n",
       "      <td>3.628577</td>\n",
       "      <td>0.171759</td>\n",
       "      <td>3.298573</td>\n",
       "      <td>0.879095</td>\n",
       "      <td>1.010986</td>\n",
       "      <td>0.390880</td>\n",
       "      <td>0.323098</td>\n",
       "      <td>0.469389</td>\n",
       "      <td>2.315486</td>\n",
       "      <td>1.962532</td>\n",
       "      <td>2.724323</td>\n",
       "      <td>1.021241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.707158e+05</td>\n",
       "      <td>4.146419</td>\n",
       "      <td>0.377172</td>\n",
       "      <td>12.016407</td>\n",
       "      <td>1.603973</td>\n",
       "      <td>1.163983</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>0.812803</td>\n",
       "      <td>1.147778</td>\n",
       "      <td>1.064330</td>\n",
       "      <td>0.978646</td>\n",
       "      <td>1.214104</td>\n",
       "      <td>1.613017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.997235e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.019180e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.047830e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.638726e+06</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     Time_Diff     Recidivate  INFRACTION_PER_SENT  \\\n",
       "count  1.315390e+05  63596.000000  131539.000000        131539.000000   \n",
       "mean   4.897019e+05      3.628577       0.171759             3.298573   \n",
       "std    3.707158e+05      4.146419       0.377172            12.016407   \n",
       "min    8.000000e+00    -13.000000       0.000000             0.000000   \n",
       "25%    1.997235e+05      1.000000       0.000000             0.000000   \n",
       "50%    4.019180e+05      2.000000       0.000000             0.000000   \n",
       "75%    7.047830e+05      5.000000       0.000000             2.000000   \n",
       "max    1.638726e+06     45.000000       1.000000           670.000000   \n",
       "\n",
       "          misd_count    felon_count  Recidivate_Risk_Level  \\\n",
       "count  131533.000000  131533.000000          131539.000000   \n",
       "mean        0.879095       1.010986               0.390880   \n",
       "std         1.603973       1.163983               0.962164   \n",
       "min         0.000000       0.000000               0.000000   \n",
       "25%         0.000000       0.000000               0.000000   \n",
       "50%         0.000000       1.000000               0.000000   \n",
       "75%         1.000000       1.000000               0.000000   \n",
       "max       125.000000      40.000000               5.000000   \n",
       "\n",
       "       Recidivate_Risk_Level_Lenient  Recidivate_Risk_Level_Harsh  \\\n",
       "count                  131539.000000                131539.000000   \n",
       "mean                        0.323098                     0.469389   \n",
       "std                         0.812803                     1.147778   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         0.000000                     0.000000   \n",
       "50%                         0.000000                     0.000000   \n",
       "75%                         0.000000                     0.000000   \n",
       "max                         5.000000                     5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level  Current_Offense_Risk_Level_Lenient  \\\n",
       "count               125172.000000                       125172.000000   \n",
       "mean                     2.315486                            1.962532   \n",
       "std                      1.064330                            0.978646   \n",
       "min                      1.000000                            1.000000   \n",
       "25%                      1.000000                            1.000000   \n",
       "50%                      2.000000                            2.000000   \n",
       "75%                      3.000000                            2.000000   \n",
       "max                      5.000000                            5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level_Harsh  sentence_count  \n",
       "count                     125172.000000   131539.000000  \n",
       "mean                           2.724323        1.021241  \n",
       "std                            1.214104        1.613017  \n",
       "min                            1.000000        0.000000  \n",
       "25%                            2.000000        0.000000  \n",
       "50%                            3.000000        0.000000  \n",
       "75%                            4.000000        1.000000  \n",
       "max                            5.000000       21.000000  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time_Diff</th>\n",
       "      <th>Recidivate</th>\n",
       "      <th>INFRACTION_PER_SENT</th>\n",
       "      <th>misd_count</th>\n",
       "      <th>felon_count</th>\n",
       "      <th>Recidivate_Risk_Level</th>\n",
       "      <th>Recidivate_Risk_Level_Lenient</th>\n",
       "      <th>Recidivate_Risk_Level_Harsh</th>\n",
       "      <th>Current_Offense_Risk_Level</th>\n",
       "      <th>Current_Offense_Risk_Level_Lenient</th>\n",
       "      <th>Current_Offense_Risk_Level_Harsh</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.280100e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32801.000000</td>\n",
       "      <td>32801.000000</td>\n",
       "      <td>32801.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26557.000000</td>\n",
       "      <td>26557.000000</td>\n",
       "      <td>26557.000000</td>\n",
       "      <td>32801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.969609e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.133563</td>\n",
       "      <td>0.104082</td>\n",
       "      <td>2.236731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.447980</td>\n",
       "      <td>2.976315</td>\n",
       "      <td>3.781263</td>\n",
       "      <td>1.521935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.793942e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.599285</td>\n",
       "      <td>0.480620</td>\n",
       "      <td>2.013134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.181862</td>\n",
       "      <td>1.175837</td>\n",
       "      <td>1.097834</td>\n",
       "      <td>2.047846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.123140e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.934410e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.333759e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.638770e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Time_Diff  Recidivate  INFRACTION_PER_SENT    misd_count  \\\n",
       "count  3.280100e+04        0.0         0.0         32801.000000  32801.000000   \n",
       "mean   8.969609e+05        NaN         NaN            20.133563      0.104082   \n",
       "std    4.793942e+05        NaN         NaN            41.599285      0.480620   \n",
       "min    8.000000e+01        NaN         NaN             0.000000      0.000000   \n",
       "25%    5.123140e+05        NaN         NaN             1.000000      0.000000   \n",
       "50%    8.934410e+05        NaN         NaN             6.000000      0.000000   \n",
       "75%    1.333759e+06        NaN         NaN            22.000000      0.000000   \n",
       "max    1.638770e+06        NaN         NaN           989.000000     20.000000   \n",
       "\n",
       "        felon_count  Recidivate_Risk_Level  Recidivate_Risk_Level_Lenient  \\\n",
       "count  32801.000000                    0.0                            0.0   \n",
       "mean       2.236731                    NaN                            NaN   \n",
       "std        2.013134                    NaN                            NaN   \n",
       "min        0.000000                    NaN                            NaN   \n",
       "25%        1.000000                    NaN                            NaN   \n",
       "50%        2.000000                    NaN                            NaN   \n",
       "75%        3.000000                    NaN                            NaN   \n",
       "max       87.000000                    NaN                            NaN   \n",
       "\n",
       "       Recidivate_Risk_Level_Harsh  Current_Offense_Risk_Level  \\\n",
       "count                          0.0                26557.000000   \n",
       "mean                           NaN                    3.447980   \n",
       "std                            NaN                    1.181862   \n",
       "min                            NaN                    1.000000   \n",
       "25%                            NaN                    3.000000   \n",
       "50%                            NaN                    3.000000   \n",
       "75%                            NaN                    5.000000   \n",
       "max                            NaN                    5.000000   \n",
       "\n",
       "       Current_Offense_Risk_Level_Lenient  Current_Offense_Risk_Level_Harsh  \\\n",
       "count                        26557.000000                      26557.000000   \n",
       "mean                             2.976315                          3.781263   \n",
       "std                              1.175837                          1.097834   \n",
       "min                              1.000000                          1.000000   \n",
       "25%                              2.000000                          3.000000   \n",
       "50%                              3.000000                          4.000000   \n",
       "75%                              4.000000                          5.000000   \n",
       "max                              5.000000                          5.000000   \n",
       "\n",
       "       sentence_count  \n",
       "count    32801.000000  \n",
       "mean         1.521935  \n",
       "std          2.047846  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          1.000000  \n",
       "75%          2.000000  \n",
       "max         27.000000  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sentences.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions look pretty good across train,test, and validate compared to dataset minus active\n",
    "# Active sentences don't look as close (most variables are fine, not Infractions though) but there's no reason \n",
    "# currently incarcerated people would be a random sample of historical sentences \n",
    "\n",
    "# Next need to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
